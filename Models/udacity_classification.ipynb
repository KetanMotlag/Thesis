{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ae3f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras import models, optimizers, backend\n",
    "from keras.layers import core, convolutional, pooling\n",
    "from sklearn import model_selection\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import skimage \n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from skimage.io import imread\n",
    "from lime import lime_image\n",
    "\n",
    "from keras.applications import inception_v3 as inc_net\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647e8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ('C:/Users/Ketan/Thesis/self-driving-car/challenges/challenge-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a05385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.io.parsers.read_csv(os.path.join(dataset, 'out.csv'))\n",
    "# # Split data into training and validation sets\n",
    "df_train, df_valid = model_selection.train_test_split(df, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f50de334",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None #default = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8da67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['angle_range'] = pd.qcut(df_train['angle'], q=10)\n",
    "df_valid['angle_range'] = pd.qcut(df_valid['angle'], q=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f14054",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['labels']= df_train['angle_range'].cat.codes\n",
    "df_valid['labels']= df_valid['angle_range'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "006d4999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['labels'] = df_train['labels'].apply(str)\n",
    "df_valid['labels'] = df_valid['labels'].apply(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf7bfaac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'udacity_training_classification' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9872/3100389497.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mudacity_training_classification\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'udacity_training_classification' is not defined"
     ]
    }
   ],
   "source": [
    "df_train.to_csv(''udacity_training_classification'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fc1b55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4491 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=dataset, x_col=\"File\", y_col=\"labels\", \n",
    "                                            class_mode=\"categorical\", target_size=(480,640), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e864f82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1123 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=datagen.flow_from_dataframe(dataframe=df_valid, directory=dataset, \n",
    "                                            x_col=\"File\", y_col=\"labels\", class_mode=\"categorical\", target_size=(480,640), \n",
    "                                            batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4ad7e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(convolutional.Convolution2D(16,3,3, input_shape=(480,640,3), activation='relu'))\n",
    "model.add(pooling.MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(convolutional.Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(pooling.MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(convolutional.Convolution2D(64, 3, 3, activation='relu'))\n",
    "model.add(pooling.MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "model.add(core.Flatten())\n",
    "model.add(core.Dense(500, activation='relu'))\n",
    "model.add(core.Dropout(.5))\n",
    "model.add(core.Dense(100, activation='relu'))\n",
    "model.add(core.Dropout(.25))\n",
    "model.add(core.Dense(20, activation='relu'))\n",
    "model.add(core.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-04), loss='categorical_crossentropy',metrics=['AUC', 'categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ffb6afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 160, 213, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 80, 107, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 35, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 6, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               192500    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 268,414\n",
      "Trainable params: 268,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1c38157",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d426f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4454d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7349f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './logs2'\n",
    "callback1 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_loss', verbose=0, \n",
    "                                               save_best_only=False, save_weights_only=False, mode='auto', \n",
    "                                               save_freq='epoch',options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "394c0b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('udacity_classification_custom_model_v2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67803b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ketan\\anaconda3\\envs\\tf-gpu-cuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 142s 966ms/step - loss: 0.6329 - auc: 0.9766 - categorical_accuracy: 0.7800 - val_loss: 0.5612 - val_auc: 0.9809 - val_categorical_accuracy: 0.8179\n",
      "INFO:tensorflow:Assets written to: .\\logs2\\assets\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 131s 937ms/step - loss: 0.6148 - auc: 0.9780 - categorical_accuracy: 0.7914 - val_loss: 0.5685 - val_auc: 0.9800 - val_categorical_accuracy: 0.8295\n",
      "INFO:tensorflow:Assets written to: .\\logs2\\assets\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 130s 928ms/step - loss: 0.5871 - auc: 0.9805 - categorical_accuracy: 0.7863 - val_loss: 0.5736 - val_auc: 0.9799 - val_categorical_accuracy: 0.8161\n",
      "INFO:tensorflow:Assets written to: .\\logs2\\assets\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 131s 934ms/step - loss: 0.5679 - auc: 0.9811 - categorical_accuracy: 0.8042 - val_loss: 0.5633 - val_auc: 0.9802 - val_categorical_accuracy: 0.8152\n",
      "INFO:tensorflow:Assets written to: .\\logs2\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20c817a9ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=20, callbacks=[callback, callback1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "064fa30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('udacity_classification_custom_model_weights_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac8f13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('udacity_classification_custom_model_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "795172bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import inception_v3 as inc_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5a580bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img_fn(path_list):\n",
    "    out = []\n",
    "    for img_path in path_list:\n",
    "        img = image.load_img((img_path), target_size=(480,640))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = inc_net.preprocess_input(x)\n",
    "        out.append(x)\n",
    "    return np.vstack(out) /2 +0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc99bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = transform_img_fn([os.path.join(r'C:/Users/Ketan/Thesis/self-driving-car/challenges/challenge-2/','1479425717280900950.jpg')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66a22f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7272626e-04, 9.8335797e-01, 1.0109666e-02, 1.5271852e-03,\n",
       "        1.8140408e-03, 1.4903632e-03, 1.4183132e-03, 4.0885689e-06,\n",
       "        1.9641282e-06, 3.6494907e-06]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46380724",
   "metadata": {},
   "outputs": [],
   "source": [
    " def open_images(inference_folder: str) -> np.ndarray:\n",
    "    \"\"\"Loads images from a folder and prepare them for inferencing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inference_folder : str\n",
    "        Location of images for inferencing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        List of images as numpy arrays transformed to fit the efficient_net model input specs.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for img in os.listdir(inference_folder):\n",
    "        img_location = os.path.join(inference_folder, img)  # create full path to image\n",
    "\n",
    "        with Image.open(img_location) as img:  # open image with pillow\n",
    "\n",
    "            img = np.array(img)\n",
    "            img = img[:, :, :3]\n",
    "            img = np.expand_dims(img, axis=0)  # add 0 dimension to fit input shape of efficient_net\n",
    "            img = inc_net.preprocess_input(img)\n",
    "\n",
    "        images.append(img)\n",
    "    images_array = np.vstack(images)  # combine images efficiently to a numpy array\n",
    "    return images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d20ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = open_images(\"C:/Users/Ketan/Thesis/self-driving-car/challenges/test_dataset1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39c6b8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479425719681268780.jpg [7.2221975e-09 1.7213597e-07 7.1565906e-04 9.4972956e-01 1.3229251e-02\n",
      " 7.5207460e-03 1.7035704e-02 3.5625370e-04 2.8775318e-03 8.5350713e-03]\n",
      "1479425719731264417.jpg [3.2595270e-07 7.3315715e-07 1.0422587e-03 7.5753844e-01 4.9150348e-02\n",
      " 8.0104377e-03 3.6861550e-02 1.2549951e-02 7.0672423e-02 6.4173587e-02]\n",
      "1479425719781262693.jpg [1.5169276e-07 7.9415749e-08 3.4231867e-04 1.8231438e-01 2.6431710e-02\n",
      " 6.6739358e-03 2.9259533e-02 1.8395272e-01 4.7569504e-01 9.5330119e-02]\n",
      "1479425719831276356.jpg [6.2930823e-08 5.6677759e-08 2.0123074e-04 3.8890791e-01 3.5094813e-02\n",
      " 4.9493317e-03 3.6107324e-02 2.0522982e-02 1.7559575e-01 3.3862060e-01]\n",
      "1479425719881419974.jpg [4.74698567e-07 3.33585376e-05 2.20506772e-04 3.23442295e-02\n",
      " 3.44644208e-03 3.73651311e-02 1.02660134e-01 9.11220685e-02\n",
      " 5.92144430e-01 1.40663296e-01]\n",
      "1479425719931414543.jpg [8.1365602e-07 8.6704567e-05 2.4341630e-04 2.2599611e-02 1.4037301e-03\n",
      " 2.3952996e-02 5.0344113e-02 3.7958350e-02 6.9601810e-01 1.6739213e-01]\n",
      "1479425719981321507.jpg [1.2903586e-06 8.2241226e-05 2.0555808e-04 2.2042086e-02 1.0927008e-03\n",
      " 2.7979808e-02 4.2962354e-02 4.3455496e-02 4.8868629e-01 3.7349221e-01]\n",
      "1479425720031300599.jpg [1.42073145e-06 1.00364814e-04 5.97680453e-04 8.84050578e-02\n",
      " 2.71135080e-03 4.40806448e-02 7.35230222e-02 1.09285139e-01\n",
      " 5.92037916e-01 8.92574564e-02]\n",
      "1479425720081346893.jpg [4.8757265e-06 1.4423690e-04 9.0781139e-04 6.3497543e-02 3.4803820e-03\n",
      " 2.1813462e-02 4.7703270e-02 1.3016707e-01 6.7505914e-01 5.7222269e-02]\n",
      "1479425720131269683.jpg [2.1737268e-14 1.6535394e-10 1.2723979e-07 5.0676083e-03 6.6735750e-01\n",
      " 8.1587628e-02 2.4575287e-01 2.2219234e-04 1.1782637e-05 2.0195996e-07]\n",
      "1479425720181373910.jpg [6.3364807e-15 7.1740724e-10 8.9612359e-07 1.0536811e-02 5.8908105e-01\n",
      " 3.5183468e-01 4.8536554e-02 9.7484253e-06 1.7846111e-07 3.8973171e-09]\n",
      "1479425720231334733.jpg [1.2209327e-15 4.0042106e-10 3.3014462e-07 8.1264274e-03 1.5868191e-01\n",
      " 7.7126729e-01 6.1919458e-02 4.5750294e-06 1.5652224e-08 7.0964559e-09]\n",
      "1479425720281331591.jpg [5.4169235e-15 2.3722690e-10 9.9848464e-08 2.1465411e-03 1.3868701e-01\n",
      " 5.9294534e-01 2.6588255e-01 3.3751881e-04 9.0326392e-07 5.2062045e-08]\n",
      "1479425720331302374.jpg [7.1775946e-19 4.7837641e-22 9.9225228e-23 1.3899318e-14 7.9062088e-18\n",
      " 1.1805742e-14 1.3541354e-12 1.2571057e-10 2.2766115e-13 1.0000000e+00]\n",
      "1479425720381363046.jpg [3.0013131e-20 2.0767748e-22 1.9037650e-22 5.6895775e-15 2.0990094e-17\n",
      " 9.1847028e-14 1.5616265e-12 6.2650454e-11 2.3246509e-13 1.0000000e+00]\n",
      "1479425720431335470.jpg [5.7089037e-23 3.3420092e-25 9.8695492e-25 7.1236748e-17 6.1164604e-19\n",
      " 6.1655969e-15 1.0972520e-13 7.3740025e-12 1.9888600e-14 1.0000000e+00]\n",
      "1479425720481412110.jpg [5.4134361e-24 1.3699786e-25 5.0932129e-26 1.5453173e-17 1.7828321e-19\n",
      " 1.3772586e-15 3.2727900e-14 3.5296717e-13 3.4175495e-15 1.0000000e+00]\n",
      "1479425720531376518.jpg [5.0648363e-23 1.2374371e-24 7.7469967e-24 3.7534440e-15 1.6890803e-17\n",
      " 1.1520922e-13 3.6829074e-13 6.1635695e-13 5.4037636e-15 1.0000000e+00]\n",
      "1479425720581393603.jpg [4.0172046e-11 5.3479632e-10 8.1189755e-06 6.6973254e-05 7.1782364e-05\n",
      " 6.5625249e-04 5.5482262e-04 1.2912499e-03 9.8672718e-01 1.0623609e-02]\n",
      "1479425720631398027.jpg [4.3426857e-10 8.3544496e-09 8.0047219e-05 3.5796192e-04 5.8154814e-04\n",
      " 5.4577105e-03 2.2407905e-03 1.2170582e-03 9.5344973e-01 3.6615130e-02]\n",
      "1479425720681517212.jpg [7.1200330e-11 4.0981187e-09 8.0275851e-05 3.5830727e-04 5.4359616e-04\n",
      " 2.3200948e-02 3.3065479e-03 9.8613615e-04 8.5247439e-01 1.1904978e-01]\n",
      "1479425720731420306.jpg [5.5271097e-11 1.8158110e-08 2.3401641e-04 1.7472472e-03 3.8985615e-03\n",
      " 3.2672203e-01 2.1695590e-02 1.4296306e-03 5.2613521e-01 1.1813778e-01]\n",
      "1479425720781425602.jpg [3.7154055e-16 1.4750878e-11 4.8930499e-08 3.1697864e-04 3.1643468e-03\n",
      " 9.4943905e-01 4.6361141e-02 4.9134775e-04 2.2705221e-04 4.9511051e-08]\n",
      "1479425720831471166.jpg [7.5065258e-17 4.3129077e-12 2.0034778e-09 6.7185215e-04 1.5568796e-03\n",
      " 9.5833606e-01 3.9411996e-02 2.0597196e-05 2.3032756e-06 2.3165909e-07]\n",
      "1479425720881517725.jpg [1.79838581e-16 1.02521784e-11 1.41420176e-09 4.15012054e-03\n",
      " 4.92757885e-03 8.49932075e-01 1.40982568e-01 6.63401124e-06\n",
      " 7.05311493e-07 2.08733979e-07]\n",
      "1479425720931436208.jpg [1.9096864e-15 1.6671236e-11 7.2894584e-09 6.8268171e-03 3.7528055e-03\n",
      " 8.2213587e-01 1.6692504e-01 3.4009735e-04 1.2923906e-05 6.4106534e-06]\n",
      "1479425720981458366.jpg [9.0981233e-12 4.7707349e-10 3.7065234e-08 1.4460072e-02 1.4408730e-04\n",
      " 3.0604379e-02 1.6692327e-01 6.0930986e-02 6.8306597e-03 7.2010660e-01]\n",
      "1479425721031504367.jpg [1.8012893e-12 1.3479576e-10 5.6067737e-09 3.4983810e-03 9.8889555e-05\n",
      " 3.9825026e-02 1.3016707e-01 1.5557357e-02 9.7594532e-04 8.0987734e-01]\n",
      "1479425721081455633.jpg [1.7523986e-12 6.4490822e-11 5.6272271e-09 2.3393838e-03 3.4467911e-04\n",
      " 1.0801342e-01 4.0168765e-01 1.0058234e-01 5.9778348e-04 3.8643476e-01]\n",
      "1479425721131548477.jpg [8.4118877e-13 2.8620308e-11 6.2996608e-09 3.8603836e-04 1.9785058e-04\n",
      " 1.6044368e-01 1.7578205e-01 3.7083566e-01 3.0192763e-03 2.8933543e-01]\n",
      "1479425721181509306.jpg [7.8479076e-15 6.5677943e-13 2.8501013e-09 3.4850859e-04 1.2137208e-04\n",
      " 3.1153029e-01 9.3467109e-02 5.9148762e-02 9.9035986e-03 5.2548033e-01]\n",
      "1479425721231458038.jpg [1.2929511e-09 1.5168479e-07 8.3812329e-06 3.3110977e-05 1.0938217e-05\n",
      " 3.1805143e-04 8.3131640e-04 1.0623160e-02 9.8718959e-01 9.8539621e-04]\n",
      "1479425721281465449.jpg [4.8651183e-10 9.9141609e-08 5.5038035e-06 7.2665453e-06 1.5509052e-06\n",
      " 1.5119520e-04 8.0855054e-05 5.0294545e-04 9.9736375e-01 1.8868829e-03]\n",
      "1479425721331544838.jpg [8.1989715e-10 1.3579623e-07 1.0637535e-05 2.6428675e-05 6.7091237e-06\n",
      " 6.1152235e-04 2.0852273e-04 2.4157560e-03 9.8975545e-01 6.9648349e-03]\n",
      "1479425721381536375.jpg [8.86494045e-10 1.10100110e-07 1.10578585e-05 3.57253775e-05\n",
      " 7.51993412e-06 1.02328626e-03 3.03234236e-04 2.54808669e-03\n",
      " 9.78733122e-01 1.73378810e-02]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_generator(images)\n",
    "images_names = os.listdir(\"C:/Users/Ketan/Thesis/self-driving-car/challenges/test_dataset\")\n",
    "for image_name, prediction in zip(images_names, predictions):\n",
    "    print(image_name, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73c5674d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7eb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82f97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu-cuda] *",
   "language": "python",
   "name": "conda-env-tf-gpu-cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
