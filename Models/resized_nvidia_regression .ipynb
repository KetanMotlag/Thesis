{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c181c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Flatten, Dense, Dropout, Cropping2D, Lambda, InputLayer\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras import losses, optimizers, metrics, backend, regularizers \n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b91edc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Union, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f1dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ('C:/Users/Ketan/Thesis/PilotNet/src/Resized1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936ac531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.io.parsers.read_csv(os.path.join(dataset, 'data_new.csv'))\n",
    "# Split data into training and validation sets\n",
    "df_train, df_val = train_test_split(df, test_size=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52717e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "277edbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36324 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=dataset, x_col=\"image\", y_col=\"angle\", \n",
    "                                            class_mode=\"raw\", target_size=(128, 228), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c9a87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9081 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "val_generator=datagen.flow_from_dataframe(dataframe=df_val, directory=dataset, x_col=\"image\", y_col=\"angle\", \n",
    "                                            class_mode=\"raw\", target_size=(128, 228), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d8825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(drop_prob = 0.2, learn_rate=0.001, constraint=maxnorm(3), reg = None, verbose = False): \n",
    "    backend.clear_session()\n",
    "    model = Sequential()\n",
    "\n",
    "    ###--- Convolutional Neural Network --- ### \n",
    "    input_shape = (128, 228, 3)\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "\n",
    "#     model.add(Cropping2D(cropping=((60, 0), (0, 0)), input_shape=input_shape))\n",
    "    # model.add(Lambda(resize, input_shape=input_shape))\n",
    "    model.add(BatchNormalization(name='r0'))\n",
    "\n",
    "    ### conv. layers \n",
    "    model.add(Convolution2D(filters=24,\n",
    "                            kernel_size=(5, 5),\n",
    "                            strides = (2, 2),\n",
    "                            activation='relu',\n",
    "                            kernel_regularizer=reg, \n",
    "                            input_shape=input_shape, \n",
    "                            ))\n",
    "    '''READ THIS try adding max pool - before min loss was 7.04'''\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization(name='r1'))\n",
    "\n",
    "    model.add(Convolution2D(filters=36,\n",
    "                            kernel_size=(5, 5),\n",
    "                            strides = (2, 2),\n",
    "                            activation='relu',\n",
    "                            kernel_regularizer=reg, \n",
    "                            ))\n",
    "    model.add(BatchNormalization(name='r2'))\n",
    "\n",
    "    model.add(Convolution2D(filters=48,\n",
    "                            kernel_size=(5, 5),\n",
    "                            strides = (2, 2),\n",
    "                            activation='relu',\n",
    "                            kernel_regularizer=reg, \n",
    "                            ))\n",
    "    model.add(BatchNormalization(name='r3'))\n",
    "\n",
    "    model.add(Convolution2D(filters=64,\n",
    "                            kernel_size=(3, 3),\n",
    "                            strides = (1, 1),\n",
    "                            activation='relu',\n",
    "                            kernel_regularizer=reg, \n",
    "                            ))\n",
    "    model.add(BatchNormalization(name='r4'))\n",
    "\n",
    "    model.add(Convolution2D(filters=64,\n",
    "                            kernel_size=(1, 1),\n",
    "                            strides = (2, 2),\n",
    "                            activation='relu',\n",
    "                            kernel_regularizer=reg, \n",
    "                            ))\n",
    "    model.add(BatchNormalization(name='r5'))\n",
    "\n",
    "    ### fully connect layers \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164, activation='relu', kernel_constraint=constraint))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "    model.add(Dense(100, activation='relu', kernel_constraint=constraint))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "    model.add(Dense(50, activation='relu', kernel_constraint=constraint))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "    model.add(Dense(10, activation='relu', kernel_constraint=constraint))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    if verbose: \n",
    "        # Summarize the model\n",
    "        model.summary()\n",
    "    \n",
    "    #compile \n",
    "    model.compile(loss='mse', optimizer=optimizers.Adam(lr=learn_rate))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "958f8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard object \n",
    "!mkdir logs5\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "#save and overwrite models when improved \n",
    "filepath=\"checkpoints/baseline_best.h5\"\n",
    "\n",
    "!mkdir checkpoints5\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "callbacks_list = [checkpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ea791ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "r0 (BatchNormalization)      (None, 128, 228, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 62, 112, 24)       1824      \n",
      "_________________________________________________________________\n",
      "r1 (BatchNormalization)      (None, 62, 112, 24)       96        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 54, 36)        21636     \n",
      "_________________________________________________________________\n",
      "r2 (BatchNormalization)      (None, 29, 54, 36)        144       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 25, 48)        43248     \n",
      "_________________________________________________________________\n",
      "r3 (BatchNormalization)      (None, 13, 25, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 23, 64)        27712     \n",
      "_________________________________________________________________\n",
      "r4 (BatchNormalization)      (None, 11, 23, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 12, 64)         4160      \n",
      "_________________________________________________________________\n",
      "r5 (BatchNormalization)      (None, 6, 12, 64)         256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1164)              5364876   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1164)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 5,586,483\n",
      "Trainable params: 5,586,005\n",
      "Non-trainable params: 478\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ketan\\anaconda3\\envs\\tf-gpu-cuda\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARN_RATE = 0.001\n",
    "DROP_PROB = 0.4\n",
    "\n",
    "control_model = build_model(drop_prob = DROP_PROB, learn_rate = LEARN_RATE, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86141bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "201a8c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ketan\\anaconda3\\envs\\tf-gpu-cuda\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1135/1135 [==============================] - 210s 177ms/step - loss: 762.9199 - val_loss: 448.3863\n",
      "Epoch 2/20\n",
      "1135/1135 [==============================] - 190s 168ms/step - loss: 572.9327 - val_loss: 384.1129\n",
      "Epoch 3/20\n",
      "1135/1135 [==============================] - 191s 168ms/step - loss: 441.0208 - val_loss: 346.7112\n",
      "Epoch 4/20\n",
      "1135/1135 [==============================] - 190s 167ms/step - loss: 394.4545 - val_loss: 319.6095\n",
      "Epoch 5/20\n",
      "1135/1135 [==============================] - 190s 167ms/step - loss: 350.7538 - val_loss: 313.5581\n",
      "Epoch 6/20\n",
      "1135/1135 [==============================] - 191s 168ms/step - loss: 358.4979 - val_loss: 270.4612\n",
      "Epoch 7/20\n",
      "1135/1135 [==============================] - 192s 169ms/step - loss: 374.4212 - val_loss: 302.8915\n",
      "Epoch 8/20\n",
      "1135/1135 [==============================] - 191s 168ms/step - loss: 347.1401 - val_loss: 257.0193\n",
      "Epoch 9/20\n",
      "1135/1135 [==============================] - 190s 167ms/step - loss: 325.9408 - val_loss: 237.9079\n",
      "Epoch 10/20\n",
      "1135/1135 [==============================] - 190s 167ms/step - loss: 316.9446 - val_loss: 219.9012\n",
      "Epoch 11/20\n",
      "1135/1135 [==============================] - 191s 168ms/step - loss: 306.8089 - val_loss: 182.3742\n",
      "Epoch 12/20\n",
      "1135/1135 [==============================] - 190s 167ms/step - loss: 289.4204 - val_loss: 180.3849\n",
      "Epoch 13/20\n",
      "1135/1135 [==============================] - 191s 168ms/step - loss: 332.4416 - val_loss: 196.8286\n",
      "Epoch 14/20\n",
      "1135/1135 [==============================] - 199s 175ms/step - loss: 301.7945 - val_loss: 227.4208\n",
      "Epoch 15/20\n",
      "1135/1135 [==============================] - 193s 170ms/step - loss: 293.3899 - val_loss: 251.5367\n",
      "Epoch 16/20\n",
      "1135/1135 [==============================] - 191s 168ms/step - loss: 291.4850 - val_loss: 295.5413\n",
      "Epoch 17/20\n",
      "1135/1135 [==============================] - 191s 168ms/step - loss: 289.9485 - val_loss: 128.3679\n",
      "Epoch 18/20\n",
      "1135/1135 [==============================] - 190s 168ms/step - loss: 280.9019 - val_loss: 164.4679\n",
      "Epoch 19/20\n",
      "1135/1135 [==============================] - 191s 168ms/step - loss: 291.2725 - val_loss: 247.9776\n",
      "Epoch 20/20\n",
      "1135/1135 [==============================] - 191s 168ms/step - loss: 284.8940 - val_loss: 135.3568\n"
     ]
    }
   ],
   "source": [
    "control_hist = control_model.fit_generator(generator = train_generator,\n",
    "                           steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                           validation_data = val_generator,\n",
    "                           validation_steps =STEP_SIZE_VALID, \n",
    "                           epochs = EPOCHS,\n",
    "                           callbacks = callbacks_list,\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88080e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_model.save('resized_nvidia_regression_v1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc22e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import glob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu-cuda] *",
   "language": "python",
   "name": "conda-env-tf-gpu-cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
