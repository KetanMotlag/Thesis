{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b730ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Union, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import History\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd067ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ('C:/Users/Ketan/Thesis/self-driving-car/challenges/challenge-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ef9bf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.io.parsers.read_csv(os.path.join(dataset, 'out.csv'))\n",
    "# # Split data into training and validation sets\n",
    "df_train, df_val = train_test_split(df, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4e9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255, rotation_range=5,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        brightness_range=(0.75, 1),\n",
    "        shear_range=0.1,\n",
    "        zoom_range=[0.75, 1],\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5eab1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4491 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=dataset, x_col=\"File\", y_col=\"angle\", \n",
    "                                            class_mode=\"raw\", target_size=(480,640), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80271e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1123 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "val_generator=datagen.flow_from_dataframe(dataframe=df_val, directory=dataset, x_col=\"File\", y_col=\"angle\", \n",
    "                                            class_mode=\"raw\", target_size=(480,640), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df50792",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (480, 640, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b265e714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9bd044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 238, 318, 24)      1824      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 238, 318, 24)      952       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 117, 157, 36)      21636     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 117, 157, 36)      468       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 57, 77, 48)        43248     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 57, 77, 48)        228       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 55, 75, 64)        27712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 55, 75, 64)        220       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 53, 73, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 53, 73, 64)        212       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 247616)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               24761700  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 50)                200       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 24,901,339\n",
      "Trainable params: 24,899,979\n",
      "Non-trainable params: 1,360\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define PilotNet model, with batch normalization included.\n",
    "def get_model(input_shape):\n",
    "    model2 = Sequential([\n",
    "        Conv2D(24, kernel_size=(5,5), strides=(2,2), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(36, kernel_size=(5,5), strides=(2,2), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(48, kernel_size=(5,5), strides=(2,2), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, kernel_size=(3,3), strides=(1,1), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, kernel_size=(3,3), strides=(1,1), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(50, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    return model2\n",
    "\n",
    "model2 = get_model(input_shape)\n",
    "#sgd = SGD(learning_rate=1e-3, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "model2.compile(optimizer='Adam', loss=\"mse\") \n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6b81501",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8938cc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "898077b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'regression_udacity1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "870a3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback1 = EarlyStopping(monitor=\"val_loss\",\n",
    "        min_delta=1,  # model should improve by at least 1%\n",
    "         # amount of epochs  with improvements worse than 1% until the model stops\n",
    "        verbose=2,\n",
    "        mode=\"min\",\n",
    "        restore_best_weights=True) # restore the best model with the lowest validation error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f530111",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback2 = ModelCheckpoint( \"./models/\" + model_name + \".h5\",\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=0,\n",
    "        save_best_only=True,  # save the best model\n",
    "        mode=\"min\",\n",
    "        save_freq=\"epoch\") # save every epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a37d5ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "140/140 [==============================] - 1231s 9s/step - loss: 0.0440 - val_loss: 0.0461\n",
      "Restoring model weights from the end of the best epoch.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fa16a98c10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=4, callbacks=[callback1, callback2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01818276",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save_weights('udacity_regression1_loss0.04_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be25c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('udacity_regression1_loss0.04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a95c0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import inception_v3 as inc_net\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7db57ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img_fn(path_list):\n",
    "    out = []\n",
    "    for img_path in path_list:\n",
    "        img = image.load_img((img_path), target_size=(480,640))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = inc_net.preprocess_input(x)\n",
    "        out.append(x)\n",
    "    return np.vstack(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "caaab030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img_fn1(path_list):\n",
    "    out = []\n",
    "    for img_path in path_list:\n",
    "        img = image.load_img((img_path), target_size=(480,640))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "#         x = inc_net.preprocess_input(x)\n",
    "        out.append(x)\n",
    "    return np.vstack(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7b45b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = transform_img_fn1([os.path.join(r'C:/Users/Ketan/Thesis/self-driving-car/challenges/challenge-2/','1479425716180631063.jpg')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6381e38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61.508663]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133fe619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu-cuda] *",
   "language": "python",
   "name": "conda-env-tf-gpu-cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
