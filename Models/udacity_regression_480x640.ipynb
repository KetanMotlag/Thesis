{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f4e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc08aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import pooling\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from sklearn import model_selection\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38f2175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5404d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e48b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ('C:/Users/Ketan/Thesis/self-driving-car/challenges/challenge-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac4cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.io.parsers.read_csv(os.path.join(dataset, 'out.csv'))\n",
    "# # Split data into training and validation sets\n",
    "df_train, df_val = model_selection.train_test_split(df, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eea3eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_id</th>\n",
       "      <th>angle</th>\n",
       "      <th>public</th>\n",
       "      <th>torque</th>\n",
       "      <th>speed</th>\n",
       "      <th>File</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1.480000e+18</td>\n",
       "      <td>-0.095993</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1479425445583437918.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>1.480000e+18</td>\n",
       "      <td>0.051884</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1479425480989617990.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>1.480000e+18</td>\n",
       "      <td>0.076301</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1479425587558231155.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>1.480000e+18</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1479425523796982853.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>1.480000e+18</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1479425586908125583.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          frame_id     angle  public  torque  speed                     File\n",
       "88    1.480000e+18 -0.095993       0     NaN    NaN  1479425445583437918.jpg\n",
       "796   1.480000e+18  0.051884       1     NaN    NaN  1479425480989617990.jpg\n",
       "2927  1.480000e+18  0.076301       0     NaN    NaN  1479425587558231155.jpg\n",
       "1652  1.480000e+18  0.031416       0     NaN    NaN  1479425523796982853.jpg\n",
       "2914  1.480000e+18  0.000348       1     NaN    NaN  1479425586908125583.jpg"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1990f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path variables\n",
    "parent_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "data_path = os.path.join(parent_path, 'dataset')\n",
    "img_front_dir_path = os.path.join(dataset)\n",
    "\n",
    "model_path = os.path.join(parent_path, 'model')\n",
    "log_path = os.path.join(model_path, 'log')\n",
    "\n",
    "csv_dir_path = os.path.join(data_path, 'csv', 'final')\n",
    "cur_file = 'C:/Users/Ketan/Thesis/self-driving-car/challenges/challenge-2/out.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa0ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_arr(p):\n",
    "    with image.load_img(p) as img:\n",
    "        img = image.img_to_array(img)\n",
    "    return img\n",
    "\n",
    "# values computed from dataset sample.\n",
    "# def normalize(img):\n",
    "#     img[:,:,0] -= 94.9449\n",
    "#     img[:,:,0] /= 58.6121\n",
    "\n",
    "#     img[:,:,1] -= 103.599\n",
    "#     img[:,:,1] /= 61.6239\n",
    "\n",
    "#     img[:,:,2] -= 92.9077\n",
    "#     img[:,:,2] /= 68.66\n",
    "    \n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d15816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define generator that loops through the data\n",
    "def generator(df, batch_size, img_shape, should_shuffle):\n",
    "    # shuffle dataframe for each epoch\n",
    "    if should_shuffle:\n",
    "        df = shuffle(df)\n",
    "        \n",
    "    img_list = df['File'].values\n",
    "    wheel_axis = df['angle'].values\n",
    "    \n",
    "    # create empty batch\n",
    "    batch_img = np.zeros((batch_size,) + img_shape)\n",
    "    batch_label = np.zeros((batch_size, 1))\n",
    "    \n",
    "    index = 0\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            img_name = img_list[index]\n",
    "            arr = img_to_arr(os.path.join(img_front_dir_path, img_name))\n",
    "            \n",
    "            batch_img[i] = arr\n",
    "            batch_label[i] = wheel_axis[index] \n",
    "            \n",
    "            index += 1\n",
    "            if index == len(img_list):\n",
    "                index = 0\n",
    "            \n",
    "        yield batch_img, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e233d5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1479425445583437918.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.File.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6c8df0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_size: 16, train_steps: 281, val_steps: 71\n"
     ]
    }
   ],
   "source": [
    "#input_shape = img_to_arr(os.path.join(img_front_dir_path, df_train['File'])).shape\n",
    "input_shape = (480, 640, 3)\n",
    "batch_size = 16\n",
    "train_steps = (df_train.shape[0] / batch_size) + 1\n",
    "val_steps = (df_val.shape[0] / batch_size) + 1\n",
    "\n",
    "print(\" batch_size: %d, train_steps: %d, val_steps: %d\" % \n",
    "      ( batch_size, train_steps, val_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca3f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5054ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = generator(df_train, batch_size, input_shape, True)\n",
    "val_batch = generator(df_val, batch_size, input_shape, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb6e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define PilotNet model, with batch normalization included.\n",
    "def get_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv2D(24, kernel_size=(5,5), strides=(2,2), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(36, kernel_size=(5,5), strides=(2,2), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(48, kernel_size=(5,5), strides=(2,2), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, kernel_size=(3,3), strides=(1,1), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, kernel_size=(3,3), strides=(1,1), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(50, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model(input_shape)\n",
    "sgd = SGD(learning_rate=1e-3, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss=\"mse\") \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93a28ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "cur_model = cur_file + '-PilotNet_v2'\n",
    "csv_logger = CSVLogger(os.path.join(log_path, cur_model + '.log'))\n",
    "\n",
    "model_file_name= os.path.join(model_path, cur_model + '-{epoch:03d}-{val_loss:.5f}.h5')\n",
    "checkpoint = ModelCheckpoint(model_file_name, verbose=0, save_best_only=True)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf7afc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './logs1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ece1c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback1 = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, monitor='val_loss', verbose=0, \n",
    "                                               save_best_only=False, save_weights_only=False, mode='auto', \n",
    "                                               save_freq='epoch',options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8418f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    model.fit_generator(train_batch, \n",
    "                        train_steps, \n",
    "                        epochs=5, \n",
    "                        verbose=1, \n",
    "                        callbacks=[csv_logger, callback1, early_stop], \n",
    "                        validation_data=val_batch, \n",
    "                        validation_steps=val_steps, \n",
    "                        initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a956a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('udacity_regression_model_weights_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece73242",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('udacity_regression_model_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42c0903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import inception_v3 as inc_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1f3f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_img_fn(path_list):\n",
    "    out = []\n",
    "    for img_path in path_list:\n",
    "        img = image.load_img((img_path), target_size=(480,640))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = inc_net.preprocess_input(x)\n",
    "        out.append(x)\n",
    "    return np.vstack(out) /2 +0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "400885e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = transform_img_fn([os.path.join(r'C:/Users/Ketan/Thesis/self-driving-car/challenges/challenge-2/','1479425441432724303.jpg')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc15b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "178ff50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1adb936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet',input_shape=(480,640,3),include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de7a03f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65e26816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "# model.add(InputLayer(input_shape=(128,380, 3)))\n",
    "model1.add(base_model)\n",
    "model1.add(pooling.MaxPooling2D())\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(256, activation='relu'))\n",
    "# model1.add(Dropout(.5))\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "# model.add(core.Dropout(.5))\n",
    "# model.add(core.Dense(10, activation='relu'))\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "sgd = SGD(learning_rate=1e-3, decay=1e-4, momentum=0.9, nesterov=True)\n",
    "\n",
    "model1.compile(optimizer=sgd, loss=\"mse\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28353231",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5da1ea2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281/281 [==============================] - 816s 3s/step - loss: 0.0432 - val_loss: 0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ketan\\anaconda3\\envs\\tf-gpu-cuda\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\logs1\\assets\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    model1.fit_generator(train_batch, \n",
    "                        train_steps, \n",
    "                        epochs=1, \n",
    "                        verbose=1, \n",
    "                        callbacks=[csv_logger, callback1, early_stop], \n",
    "                        validation_data=val_batch, \n",
    "                        validation_steps=val_steps, \n",
    "                        initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "700dfd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save_weights('udacity_tl_regression_weights_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6091bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('udacity_tl_regression_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ecca261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250c300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6b304f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu-cuda] *",
   "language": "python",
   "name": "conda-env-tf-gpu-cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
