{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a1bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Flatten, Dense, Dropout, Cropping2D, Lambda, InputLayer\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras import losses, optimizers, metrics, backend, regularizers \n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748e034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Union, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faefb735",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ('C:/Users/Ketan/Thesis/self-driving-car/challenges/resized_dataset_udacity_320x240')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65fa41e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.io.parsers.read_csv(os.path.join(dataset, 'out.csv'))\n",
    "# Split data into training and validation sets\n",
    "df_train, df_val = train_test_split(df, test_size=.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c55e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6485be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4491 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(dataframe=df_train, directory=dataset, x_col=\"File\", y_col=\"angle\", \n",
    "                                            class_mode=\"raw\", target_size=(240, 320), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5317c7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1123 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "val_generator=datagen.flow_from_dataframe(dataframe=df_val, directory=dataset, x_col=\"File\", y_col=\"angle\", \n",
    "                                            class_mode=\"raw\", target_size=(240, 320), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "305ae4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(drop_prob = 0.2, learn_rate=0.001, constraint=maxnorm(3), reg = None, verbose = False): \n",
    "    backend.clear_session()\n",
    "    model = Sequential()\n",
    "\n",
    "    ###--- Convolutional Neural Network --- ### \n",
    "    input_shape = (240, 320, 3)\n",
    "    model.add(InputLayer(input_shape=input_shape))\n",
    "\n",
    "#     model.add(Cropping2D(cropping=((60, 0), (0, 0)), input_shape=input_shape))\n",
    "    # model.add(Lambda(resize, input_shape=input_shape))\n",
    "    model.add(BatchNormalization(name='r0'))\n",
    "\n",
    "    ### conv. layers \n",
    "    model.add(Convolution2D(filters=24,\n",
    "                            kernel_size=(5, 5),\n",
    "                            strides = (2, 2),\n",
    "                            activation='relu',\n",
    "                            kernel_regularizer=reg, \n",
    "                            input_shape=input_shape, \n",
    "                            ))\n",
    "    '''READ THIS try adding max pool - before min loss was 7.04'''\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization(name='r1'))\n",
    "\n",
    "    model.add(Convolution2D(filters=36,\n",
    "                            kernel_size=(5, 5),\n",
    "                            strides = (2, 2),\n",
    "                            activation='relu',\n",
    "                            kernel_regularizer=reg, \n",
    "                            ))\n",
    "    model.add(BatchNormalization(name='r2'))\n",
    "\n",
    "    model.add(Convolution2D(filters=48,\n",
    "                            kernel_size=(5, 5),\n",
    "                            strides = (2, 2),\n",
    "                            activation='relu',\n",
    "                            kernel_regularizer=reg, \n",
    "                            ))\n",
    "    model.add(BatchNormalization(name='r3'))\n",
    "\n",
    "    model.add(Convolution2D(filters=64,\n",
    "                            kernel_size=(3, 3),\n",
    "                            strides = (1, 1),\n",
    "                            activation='relu',\n",
    "                            kernel_regularizer=reg, \n",
    "                            ))\n",
    "    model.add(BatchNormalization(name='r4'))\n",
    "\n",
    "    model.add(Convolution2D(filters=64,\n",
    "                            kernel_size=(1, 1),\n",
    "                            strides = (2, 2),\n",
    "                            activation='relu',\n",
    "                            kernel_regularizer=reg, \n",
    "                            ))\n",
    "    model.add(BatchNormalization(name='r5'))\n",
    "\n",
    "    ### fully connect layers \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1164, activation='relu', kernel_constraint=constraint))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "    model.add(Dense(100, activation='relu', kernel_constraint=constraint))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "    model.add(Dense(50, activation='relu', kernel_constraint=constraint))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "    model.add(Dense(10, activation='relu', kernel_constraint=constraint))\n",
    "    model.add(Dropout(drop_prob))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    if verbose: \n",
    "        # Summarize the model\n",
    "        model.summary()\n",
    "    \n",
    "    #compile \n",
    "    model.compile(loss='mse', optimizer=optimizers.Adam(lr=learn_rate))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d683b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard object \n",
    "!mkdir logs6\n",
    "tensorboard = TensorBoard(log_dir='./logs6', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "#save and overwrite models when improved \n",
    "filepath=\"checkpoints/baseline_best.h5\"\n",
    "\n",
    "!mkdir checkpoints6\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "callbacks_list = [checkpoint, tensorboard, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cff0a129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "r0 (BatchNormalization)      (None, 240, 320, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 118, 158, 24)      1824      \n",
      "_________________________________________________________________\n",
      "r1 (BatchNormalization)      (None, 118, 158, 24)      96        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 57, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "r2 (BatchNormalization)      (None, 57, 77, 36)        144       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 37, 48)        43248     \n",
      "_________________________________________________________________\n",
      "r3 (BatchNormalization)      (None, 27, 37, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 35, 64)        27712     \n",
      "_________________________________________________________________\n",
      "r4 (BatchNormalization)      (None, 25, 35, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 18, 64)        4160      \n",
      "_________________________________________________________________\n",
      "r5 (BatchNormalization)      (None, 13, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 14976)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1164)              17433228  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1164)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               116500    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 17,654,835\n",
      "Trainable params: 17,654,357\n",
      "Non-trainable params: 478\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARN_RATE = 0.001\n",
    "DROP_PROB = 0.4\n",
    "\n",
    "control_model = build_model(drop_prob = DROP_PROB, learn_rate = LEARN_RATE, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4126c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51b327f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "140/140 [==============================] - 293s 2s/step - loss: 1.0736 - val_loss: 0.0491\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 272s 2s/step - loss: 0.0521 - val_loss: 0.0415\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 285s 2s/step - loss: 0.0476 - val_loss: 0.0416\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 280s 2s/step - loss: 0.0617 - val_loss: 0.0419\n"
     ]
    }
   ],
   "source": [
    "control_hist = control_model.fit_generator(generator = train_generator,\n",
    "                           steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                           validation_data = val_generator,\n",
    "                           validation_steps =STEP_SIZE_VALID, \n",
    "                           epochs = EPOCHS,\n",
    "                           callbacks = callbacks_list,\n",
    "                           verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9304951",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_model.save('resized_udacity_regression_v2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7adbb7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc81c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import inception_v3 as inc_net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79850bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46d83704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_images(inference_folder: str) -> np.ndarray:\n",
    "    \"\"\"Loads images from a folder and prepare them for inferencing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inference_folder : str\n",
    "        Location of images for inferencing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        List of images as numpy arrays transformed to fit the efficient_net model input specs.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    for img in os.listdir(inference_folder):\n",
    "        img_location = os.path.join(inference_folder, img)  # create full path to image\n",
    "\n",
    "        with Image.open(img_location) as img:  # open image with pillow\n",
    "\n",
    "            img = np.array(img)\n",
    "            img = img[:, :, :3]\n",
    "            img = np.expand_dims(img, axis=0)  # add 0 dimension to fit input shape of efficient_net\n",
    "            img = inc_net.preprocess_input(img)\n",
    "\n",
    "        images.append(img)\n",
    "    images_array = np.vstack(images)  # combine images efficiently to a numpy array\n",
    "    return images_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34dc13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = open_images(\"C:/Users/Ketan/Thesis/self-driving-car/challenges/test_dataset2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12d4e091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479425719681268780.jpg [-0.29937765]\n",
      "1479425719731264417.jpg [-0.2768441]\n",
      "1479425719781262693.jpg [-0.05526823]\n",
      "1479425719831276356.jpg [-0.01969705]\n",
      "1479425719881419974.jpg [0.13547224]\n",
      "1479425719931414543.jpg [0.04343991]\n",
      "1479425719981321507.jpg [0.61118335]\n",
      "1479425720031300599.jpg [0.54303086]\n",
      "1479425720081346893.jpg [0.44364884]\n",
      "1479425720131269683.jpg [0.42185518]\n",
      "1479425720181373910.jpg [0.6092737]\n",
      "1479425720231334733.jpg [0.47977987]\n",
      "1479425720281331591.jpg [0.8771286]\n",
      "1479425720331302374.jpg [0.57536685]\n",
      "1479425720381363046.jpg [0.8274342]\n",
      "1479425720431335470.jpg [0.56299365]\n",
      "1479425720481412110.jpg [1.9465857]\n",
      "1479425720531376518.jpg [1.9624428]\n",
      "1479425720581393603.jpg [2.1463106]\n",
      "1479425720631398027.jpg [1.8737742]\n",
      "1479425720681517212.jpg [1.9571255]\n"
     ]
    }
   ],
   "source": [
    "predictions = control_model.predict_generator(images)\n",
    "images_names = os.listdir(\"C:/Users/Ketan/Thesis/self-driving-car/challenges/test_dataset\")\n",
    "for image_name, prediction in zip(images_names, predictions):\n",
    "    print(image_name, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ad9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu-cuda] *",
   "language": "python",
   "name": "conda-env-tf-gpu-cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
